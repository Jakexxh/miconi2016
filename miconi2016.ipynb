{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def S(X):\n",
    "    return X**3\n",
    "\n",
    "class Population:\n",
    "    \n",
    "### Miconi's bioRxiv paper parameters\n",
    "#    def __init__(self, M, N=200, g=1.5, tau=0.030, dt=1e-3, bias=4, \n",
    "#                 alpha_sta=0.05, eta=0.5, alpha_trace=0.33, perturb_rate=3.0):\n",
    "## Remark: in Miconi's code values depending on dt assume a dt at 1 ms (i.e. dt=1e-3).\n",
    "##         Thus, if you want to reproduce Miconi's experiment, do not change dt parameter.\n",
    "##         Code of Miconi we consider:\n",
    "##             On 2016/06/29, available at:\n",
    "##             https://github.com/ThomasMiconi/BiologicallyPlausibleLearningRNN/blob/master/dnms/net.cpp\n",
    "######\n",
    "### Our parameters\n",
    "    def __init__(self, M, N=200, g=1.5, tau=0.030, dt=1e-3, bias=3, \n",
    "                 alpha_sta=0.05, eta=0.5, alpha_trace=0.33, perturb_rate=3.0):\n",
    "        \"\"\"\n",
    "        alpha_sta:  discounting factor for the short term average (assuming dt = 1 ms) (i.e. trace of X)\n",
    "        \"\"\"\n",
    "        self.M, self.N = M, N\n",
    "        self.g   = g\n",
    "        self.tau = tau\n",
    "        self.t, self.dt = 0, dt\n",
    "        self.eta, self.alpha_trace, self.alpha_sta = eta, alpha_trace, alpha_sta\n",
    "        self.perturb_rate = perturb_rate\n",
    "        self.bias = np.random.choice(N, size=bias+1, replace=False)\n",
    "        self._ouput = self.bias[-1] # output neuron is the last bias (trick to not select the output within the biais neurons)\n",
    "        self.bias = self.bias[:-1]\n",
    "        \n",
    "        self.B = np.random.uniform(low=-1, high=1, size=(N, M))\n",
    "        self.J = np.random.normal(loc=0.0, scale=np.sqrt(self.g**2/self.N), size=(N, N))\n",
    "        self.R_expected = {} # history of rewards by trial type\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.X = np.random.uniform(low=-0.1, high=0.1, size=(self.N, 1))\n",
    "        self.e = np.zeros((self.N, self.N))\n",
    "        \n",
    "        self.X_sta = np.copy(self.X)\n",
    "        self.t = 0\n",
    "        \n",
    "        #more info values\n",
    "        self.cummulated_abs_sum_perturbation = 0.\n",
    "        self.cummulated_nr_nr_perturbated = 0\n",
    "        \n",
    "    def output(self):\n",
    "        return np.tanh(self.X[self._ouput][0])\n",
    "        \n",
    "    def sta_X(self):\n",
    "        \"\"\"Short-term average of X i.e. trace of X\"\"\"\n",
    "        return np.mean(self._sta_X, axis=0)\n",
    "        \n",
    "    def step(self, U):\n",
    "        \"\"\"Advance time by self.dt\"\"\"\n",
    "        #self.X[self.bias] = 1.0\n",
    "        perturb_flags = np.random.random((self.N, 1)) < (self.dt*self.perturb_rate)\n",
    "        perturb = perturb_flags * np.random.uniform(low=-0.5, high=0.5, size=(self.N, 1))\n",
    "        \n",
    "        ### Because if lines 45, 337 and 339 in Miconi's dnms/net.cpp\n",
    "        # Operations done:\n",
    "        #   modul(nn) = (-1.0 + 2.0 * Uniform(myrng));\n",
    "        #   modul *= ALPHAMODUL;\n",
    "        perturb = perturb * 16 * 2 \n",
    "        \n",
    "        if self.t <= 0.003: ### Because of line 33 in Miconi's dnms/net.cpp\n",
    "            perturb = np.zeros(perturb.shape)\n",
    "            \n",
    "        #more info values\n",
    "        self.cummulated_abs_sum_perturbation += np.sum(np.abs(perturb))\n",
    "        self.cummulated_nr_nr_perturbated += np.sum(1*perturb_flags) # cummulated neuron number perturbated\n",
    "            \n",
    "        A = np.tanh(self.X) # activation a t-1                                                           # Equation 2\n",
    "        \n",
    "        self.X += self.dt/self.tau*(-self.X + np.dot(self.J, A) + np.dot(self.B, U) + perturb)           # Equation 1\n",
    "        #self.X = (1-self.dt/self.tau)*self.X + (self.dt/self.tau)*(np.dot(self.J, A) + np.dot(self.B, U) + perturb)           # Equation 1\n",
    "        #self.X = (1-self.dt/self.tau)*A + (self.dt/self.tau)*(np.dot(self.J, A) + np.dot(self.B, U) + perturb)\n",
    "        self.t += self.dt\n",
    "        \n",
    "        ### Because if lines 347 in Miconi's dnms/net.cpp\n",
    "        self.X[self.bias] = np.array([1.0, 1.0, -1.0]).reshape(3,1)\n",
    "        \n",
    "        self.X_sta = self.alpha_sta * self.X_sta + (1 - self.alpha_sta) * self.X\n",
    "        self.e += np.dot(A, S(self.X - self.X_sta).T)                                                    # Equation 3\n",
    "        \n",
    "    def end_trial(self, inputs, R):\n",
    "        inputs = tuple(tuple(map(tuple, e)) for e in inputs) # hashable inputs\n",
    "        if inputs not in self.R_expected:\n",
    "            self.R_expected[inputs] = 0.0\n",
    "        self.R_expected[inputs] = self.alpha_trace*self.R_expected[inputs] + (1-self.alpha_trace)*R      # Equation 5\n",
    "\n",
    "        delta_J = - self.eta * self.R_expected[inputs] * self.e * (R - self.R_expected[inputs])          # Equation 4\n",
    "        print('% of clipped values', np.sum(1.*np.abs(delta_J)>1e-4)/float(len(delta_J)), '%')\n",
    "        self.J += np.clip(delta_J, -1e-4, 1e-4)\n",
    "        print('delta_J', np.max(np.abs(delta_J)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trial(pop, U_1, U_2):\n",
    "    U_zero = np.zeros((pop.M, 1))\n",
    "    outputs = []\n",
    "    \n",
    "    while pop.t <= 0.200:\n",
    "        pop.step(U_1)\n",
    "    while pop.t <= 0.400:\n",
    "        pop.step(U_zero)\n",
    "    while pop.t <= 0.600:\n",
    "        pop.step(U_2)\n",
    "    while pop.t <= 0.700:\n",
    "        pop.step(U_zero)\n",
    "    while pop.t <= 1.0:\n",
    "        pop.step(U_zero)\n",
    "        outputs.append(pop.output())\n",
    "\n",
    "    target = 1.0\n",
    "    if np.all(U_1 == U_2):\n",
    "        target = -1.0\n",
    "        \n",
    "    R = np.mean(np.abs(target - np.array(outputs))) # computing reward\n",
    "    pop.end_trial([U_1, U_2], R)\n",
    "    \n",
    "    return R, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of clipped values 0.0 %\n",
      "delta_J 2.98232203887e-05\n",
      "---\n",
      "000 BB: 1.3225471460958371\n",
      "Abs sum of perturbations during the trial for all neurons 79127.9248942\n",
      "Total number of perturbations during the trial for all neurons 9905\n",
      "% of clipped values 0.0 %\n",
      "delta_J 1.92373246291e-06\n",
      "---\n",
      "001 AA: 0.35794716215684125\n",
      "Abs sum of perturbations during the trial for all neurons 80796.8900015\n",
      "Total number of perturbations during the trial for all neurons 10039\n",
      "% of clipped values 0.0 %\n",
      "delta_J 1.57551827248e-05\n",
      "---\n",
      "002 BB: 1.445988083338908\n",
      "Abs sum of perturbations during the trial for all neurons 79807.7281453\n",
      "Total number of perturbations during the trial for all neurons 10127\n",
      "% of clipped values 0.0 %\n",
      "delta_J 5.87840842806e-06\n",
      "---\n",
      "003 AA: 0.7160728163766605\n",
      "Abs sum of perturbations during the trial for all neurons 79895.3895265\n",
      "Total number of perturbations during the trial for all neurons 10044\n",
      "% of clipped values 0.0 %\n",
      "delta_J 5.99749401849e-06\n",
      "---\n",
      "004 BB: 1.0132532456798677\n",
      "Abs sum of perturbations during the trial for all neurons 80001.1896576\n",
      "Total number of perturbations during the trial for all neurons 10049\n",
      "% of clipped values 0.0 %\n",
      "delta_J 1.55235301401e-05\n",
      "---\n",
      "005 AB: 0.9529219369705377\n",
      "Abs sum of perturbations during the trial for all neurons 78324.2227617\n",
      "Total number of perturbations during the trial for all neurons 9880\n",
      "% of clipped values 0.0 %\n",
      "delta_J 3.72621611465e-05\n",
      "---\n",
      "006 BA: 1.6465003073781004\n",
      "Abs sum of perturbations during the trial for all neurons 78875.4782225\n",
      "Total number of perturbations during the trial for all neurons 9848\n",
      "% of clipped values 0.0 %\n",
      "delta_J 3.51310828834e-06\n",
      "---\n",
      "007 AB: 0.8348709852043632\n",
      "Abs sum of perturbations during the trial for all neurons 81203.4641821\n",
      "Total number of perturbations during the trial for all neurons 10114\n",
      "% of clipped values 0.0 %\n",
      "delta_J 1.31620106838e-05\n",
      "---\n",
      "008 BA: 1.512617803111312\n",
      "Abs sum of perturbations during the trial for all neurons 79456.482172\n",
      "Total number of perturbations during the trial for all neurons 9939\n",
      "% of clipped values 0.0 %\n",
      "delta_J 4.49335074925e-06\n",
      "---\n",
      "009 AB: 0.9920491343935987\n",
      "Abs sum of perturbations during the trial for all neurons 78721.02661\n",
      "Total number of perturbations during the trial for all neurons 9904\n",
      "% of clipped values 0.0 %\n",
      "delta_J 8.03456436335e-07\n",
      "---\n",
      "010 AB: 0.9540570704515092\n",
      "Abs sum of perturbations during the trial for all neurons 80216.2140031\n",
      "Total number of perturbations during the trial for all neurons 10089\n",
      "% of clipped values 0.0 %\n",
      "delta_J 3.99978858291e-06\n",
      "---\n",
      "011 BB: 0.9216949044022477\n",
      "Abs sum of perturbations during the trial for all neurons 78761.8416321\n",
      "Total number of perturbations during the trial for all neurons 9874\n",
      "% of clipped values 0.0 %\n",
      "delta_J 4.74612446984e-06\n",
      "---\n",
      "012 BA: 1.2175653792953105\n",
      "Abs sum of perturbations during the trial for all neurons 79831.2928321\n",
      "Total number of perturbations during the trial for all neurons 10008\n",
      "% of clipped values 0.0 %\n",
      "delta_J 5.82656155219e-06\n",
      "---\n",
      "013 BB: 1.175099110496319\n",
      "Abs sum of perturbations during the trial for all neurons 78824.7826017\n",
      "Total number of perturbations during the trial for all neurons 9952\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ff5b7049d2df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mU_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mU_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_B\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mU_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mU_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_B\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'---'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-e26558ea72b3>\u001b[0m in \u001b[0;36mtrial\u001b[1;34m(pop, U_1, U_2)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mpop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_zero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mpop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.600\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mpop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.700\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_zero\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-61abda0cd3ed>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, U)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_sta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_sta\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_sta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha_sta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_sta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m                                                    \u001b[1;31m# Equation 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mend_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "U_A    = np.array([[1], [0]])\n",
    "U_B    = np.array([[0], [1]])\n",
    "\n",
    "pop = Population(2, N=200, perturb_rate=50.0)\n",
    "for i in range(10000): # takes a long time.\n",
    "    idx1, idx2 = np.random.choice(2), np.random.choice(2)\n",
    "    U_1 = [U_A, U_B][idx1]\n",
    "    U_2 = [U_A, U_B][idx2]\n",
    "    R, outputs = trial(pop, U_1, U_2)\n",
    "    \n",
    "    print('---')\n",
    "    print(\"{:03d} {}{}: {}\".format(i, ['A', 'B'][idx1], ['A', 'B'][idx2], R))\n",
    "    print('Abs sum of perturbations during the trial for all neurons', pop.cummulated_abs_sum_perturbation)\n",
    "    print('Total number of perturbations during the trial for all neurons', pop.cummulated_nr_nr_perturbated)\n",
    "    pop.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
