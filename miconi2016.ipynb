{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def S(X):\n",
    "    return X**3\n",
    "\n",
    "class Population:\n",
    "    \n",
    "    def __init__(self, M, N=200, g=1.5, tau=0.030, dt=1e-3, bias=4, \n",
    "                 alpha_sta=0.05, eta=0.5, alpha_trace=0.33, perturb_rate=3.0):\n",
    "        \"\"\"\n",
    "        alpha_sta:  discounting factor for the short term average (assuming dt = 1 ms)\n",
    "        \"\"\"\n",
    "        self.M, self.N = M, N\n",
    "        self.g   = g\n",
    "        self.tau = tau\n",
    "        self.t, self.dt = 0, dt\n",
    "        self.eta, self.alpha_trace, self.alpha_sta = eta, alpha_trace, alpha_sta\n",
    "        self.perturb_rate = perturb_rate\n",
    "        self.bias = np.random.choice(N, size=5, replace=False)\n",
    "        self._ouput = np.random.choice(N, size=1, replace=False)[0] # output neuro\n",
    "        self.bias = self.bias[:-1]\n",
    "        \n",
    "        self.B = np.random.uniform(low=-1, high=1, size=(N, M))\n",
    "        self.J = np.random.normal(loc=0.0, scale=self.g**2/self.N, size=(N, N))\n",
    "        self.R_expected = {} # history of rewards by trial type\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.X = np.random.uniform(low=-0.1, high=0.1, size=(self.N, 1))\n",
    "        self.e = np.zeros((self.N, self.N))\n",
    "        \n",
    "        self.X_sta = np.copy(self.X)\n",
    "        self.t = 0\n",
    "        \n",
    "    def output(self):\n",
    "        return np.tanh(self.X[self._ouput][0])\n",
    "        \n",
    "    def sta_X(self):\n",
    "        \"\"\"Short-term average of X\"\"\"\n",
    "        return np.mean(self._sta_X, axis=0)\n",
    "        \n",
    "    def step(self, U):\n",
    "        \"\"\"Advance time by self.dt\"\"\"\n",
    "        self.X[self.bias] = 1.0\n",
    "        perturb_flags = np.random.random((self.N, 1)) < (self.dt*self.perturb_rate)\n",
    "        perturb = perturb_flags * np.random.uniform(low=-0.5, high=0.5, size=(self.N, 1))\n",
    "            \n",
    "        A = np.tanh(self.X) # activation a t-1                                                           # Equation 2\n",
    "        self.X += self.dt/self.tau*(-self.X + np.dot(self.J, A) + np.dot(self.B, U) + perturb)           # Equation 1\n",
    "        self.X = np.clip(self.X, -1.0, 1.0) # necessary ?\n",
    "        self.t += self.dt\n",
    "        \n",
    "        self.X_sta = self.alpha_sta * self.X_sta + (1 - self.alpha_sta) * self.X\n",
    "        self.e += np.dot(A, S(self.X - self.X_sta).T)                                                      # Equation 3\n",
    "        \n",
    "    def end_trial(self, inputs, R):\n",
    "        inputs = tuple(tuple(map(tuple, e)) for e in inputs) # hashable inputs\n",
    "        if not inputs in self.R_expected:\n",
    "            self.R_expected[inputs] = 0.0\n",
    "        self.R_expected[inputs] = self.alpha_trace*self.R_expected[inputs] + (1-self.alpha_trace)*R      # Equation 5\n",
    "\n",
    "        delta_J = - self.eta * self.R_expected[inputs] * self.e * (R - self.R_expected[inputs])                                          # Equation 4\n",
    "        self.J += np.clip(delta_J, -1e-4, 1e-4)\n",
    "        print('delta_J', np.max(np.abs(delta_J)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trial(pop, U_1, U_2):\n",
    "    U_zero = np.zeros((pop.M, 1))\n",
    "    outputs = []\n",
    "    \n",
    "    while pop.t <= 0.200:\n",
    "        pop.step(U_1)\n",
    "    while pop.t <= 0.400:\n",
    "        pop.step(U_zero)\n",
    "    while pop.t <= 0.600:\n",
    "        pop.step(U_2)\n",
    "    while pop.t <= 0.700:\n",
    "        pop.step(U_zero)\n",
    "    while pop.t <= 1.0:\n",
    "        pop.step(U_zero)\n",
    "        outputs.append(pop.output())\n",
    "\n",
    "    target = 1.0\n",
    "    if np.all(U_1 == U_2):\n",
    "        target = -1.0\n",
    "        \n",
    "    R = np.mean(np.abs(target - np.array(outputs))) # computing reward\n",
    "    pop.end_trial([U_1, U_2], R)\n",
    "    \n",
    "    return R, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "U_A    = np.array([[1], [0]])\n",
    "U_B    = np.array([[0], [1]])\n",
    "\n",
    "pop = Population(2, N=200, perturb_rate=50.0)\n",
    "for i in range(10000): # takes a long time.\n",
    "    idx1, idx2 = np.random.choice(2), np.random.choice(2)\n",
    "    U_1 = [U_A, U_B][idx1]\n",
    "    U_2 = [U_A, U_B][idx2]\n",
    "    R, outputs = trial(pop, U_1, U_2)\n",
    "    \n",
    "    pop.reset()\n",
    "    print(\"{:03d} {}{}: {}\".format(i, ['A', 'B'][idx1], ['A', 'B'][idx2], R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
